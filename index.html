<head>
  <style type="text/css">
    body {
  font-family: Verdana, Geneva, Arial, sans-serif;
  font-family: times;
  line-height: 1.5em;
      font-size: 17px;
}
h1 {
  line-height: 1.5em;
}
    h1, h2, h3, h4 {
  font-weight: normal;
}
h1 {
   font-size: 170%;
}
h2 {
  font-size: 150%;
}
h3 {
  font-size: 130%;
}
h4 {
  font-size: 110%;
}
th {
  border: 0px;
  font-weight: normal;
  padding: 5px;
}
td {
  border: 1px solid black;
  padding: 6px;
}
table {
  border-collapse: collapse;
  margin-top: 5px;
  margin-bottom: 15px;
}
caption {
  padding-top: 8px;
}
p {
  margin: 10px 15px 10px 15px;
}
.bgo {
  background-color: #FF9933
}

.bgy {
  background-color: #FFFF33
}
.bgo2 {
  background-color: #FFFF33
}

.bgr {
  background-color: #CC0000
}
.bgr2 {
  background-color: #D63333
}
 .bgg {
  background-color: #33AA00
}
.bgg2 {
  background-color: #90EE90
}

.bgl {
  background-color: #33FF00
}

.bgb {
  background-color: #0066CC
}
.not {
    text-decoration: overline;
}
.tgy {
  color: #FFFF33
}
#footer {
  font-size: 75%;
  text-align: center;
  line-height: normal;
  margin-top: 30px;
}
.indent1 {
    margin-left:50px;
}
.indent2 {
    margin-left:100px;
}
.indent3 {
    margin-left:150px;
}
.fcr2 {
  color: red
    }   
  </style>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-50379532-1', 'google.com');
  ga('send', 'pageview');

</script>
</head>
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <meta name="description" content="A radically different approach to an Expert System" />
  <meta name="keywords" content="Karnaugh Map,Automated Learning,Combinatorial Explosion,Grey Code,Expert System" />
  <meta name="author" content="Earl Dukerschein" />
<body>
  <h1><a id="KM"></a>Some thoughts on Karnaugh Maps, Sparse Karnaugh Maps, Automated Learning and Experimentation, State-Change Rules and the Combinatorial Explosion</h1>
  <h2>Background</h2>
  <div id="intro">
  <p>
 Around 1979, I took a class in college about computer "organization", i.e. gates, ALU, microcode
        and so on.
 Part of the class covered Karnaugh Maps.
 My professor liked to draw K-Maps with three bits on each axis.
 Then he showed us problems that were solved with the K-Map.
 Outside of class, I tried some problems on my own.
 I was able to get a few problems to work, but most did not.
        I was sure I had applied all the principles we discussed in class, so I felt there was a problem
        with the K-Map, I just did not know what it was. 
</p>
  </div>
  <div id="kmaps">
  <h2>Some years later ...</h2>
  <p>
 I started thinking about K-Maps again.
 I eventually saw the solution to the problem I encountered in college.
  </p>
  <p>
 Consider a 2-bit axis on a K-Map: 00, 01, 11, 10.
 It is arranged so that each adjacent pair of bit patterns are different by one bit.
 This includes horizontal wrap-around, so 00 and 10 are considered to be adjacent.
 Given any bit pattern on the axis, you know there are "number of bits", or in this case two,
 bit patterns that are different by one bit.
 For example, the bit pattern 00 is different, by one bit, from 01 and 10.
 On the 2-bit axis 00 is adjacent to both 01 and 10.
  </p>
 <p>
    I find it helpful to identify each K-Map square using the base 16 equivalent of its bit pattern.
 </p>

 <table class="indent1">
 <caption>A 2-bit by 2-bit Karnaugh Map</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td>1</td>
  <td class="bgo">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgo">5</td>
  <td class="bgy">7</td>
  <td class="bgo">6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td>D</td>
  <td class="bgo">F</td>
  <td>E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td>9</td>
  <td>B</td>
  <td>A</td>
    </tr>
 </table> 

  <p>
 Now consider a 3-bit axis, similar to the one used by my professor in college:
 000, 001, 011, 010, 110, 111, 101, 100.
 This is sometimes called <a href="https://secure.wikimedia.org/wikipedia/en/wiki/Gray_code">Grey Code</a>.
 For the bit pattern 000 there should be "number of bits", in this case three, bit patterns that are different by one bit.
 They are 100, 010 and 001.
 On a K-Map axis, any bit pattern can only be adjacent to two other bit patterns.
 In this case, the bit pattern 000 is adjacent to 100 and 001, but not 010.
 A similar situation exists for all the bit patterns on the axis, the 3-bit axis has lost 1/3 of the possible adjacent pairs.  
  </p>

 <table class="indent1">
 <caption>A 1-bit by 3-bit Karnaugh Map</caption>
  <tr>
   <th></th>
   <th>000</th>
   <th>001</th>
   <th>011</th>
   <th>010</th>
   <th>110</th>
   <th>111</th>
   <th>101</th>
   <th>100</th>
  </tr>
  <tr style="text-align:center;">
   <th>0</th>
   <td>0</td>
   <td>1</td>
   <td class="bgo">3</td>
   <td>2</td>
   <td class="bgo">6</td>
   <td class="bgy">7</td>
   <td class="bgo">5</td>
   <td>4</td>
  </tr>
  <tr style="text-align:center;">
   <th>1</th>
   <td>8</td>
   <td>9</td>
   <td>B</td>
   <td>A</td>
   <td>E</td>
   <td class="bgo">F</td>
   <td>D</td>
   <td>C</td>
  </tr>
 </table>
 
  <p>
 A 2-bit by 2-bit K-Map contains 4 bits on its axes.
 A 1-bit by 3-bit K-Map contains 4 bits on its axes.
 Having the same number of bits, they should be equivalent.
 You can see in the 2x2 K-Map, above, that the squares F, 6, 5 and 3 are adjacent to square 7.
 In the 1x3 K-Map, above, squares F, 6 and 5 are adjacent to square 7, but square 3 is not.
 Neither horizontal nor vertical wrap-around will bring them together.
 So you can draw the union of 7 and 3 on the 2x2 K-Map, but not on the 1x3 K-Map.
 A similar situation can be shown for each of the 16 squares.
 <i>The two K-Maps are not equivalent</i>.
 The 2x2 K-Map is superior to the 1x3 K-Map because it allows you to
 draw all possible logical combinations of squares, while the 1x3 K-Map does not.
  </p>
  <p>
 So you can use a drawn K-Map with two bits on each axis, but any higher number of bits
 on one axis means you lose some optimal solutions.
 With four bits on an axis, you lose 1/2 of the possible adjacent pairs.
 It gets worse with each bit you add.
  </p>
  <p>
   <a href="https://secure.wikimedia.org/wikipedia/en/wiki/Gray_code">Grey Code</a>, used in a K-Map axis, works for one or two bits, but for higher numbers of bits, it is misleading.
  </p>
  <h2>Improving the definition of the Karnaugh Map</h2>
  <p>
 The requirement that <i>All adjacent bit patterns should be different by one bit</i> is
 always taught to students learning about K-Maps.
 The 2-bit and 3-bit axes, discussed above, satisfy that requirement,
 but the 2-bit axis works and the 3-bit axis only partially works.
  </p>
  <p>
 It is more accurate to say <i>All bit patterns different by one bit must be adjacent</i>,
 to allow drawing their union.
 The 2-bit axis satisfies this requirement and works, the 3-bit axis does not satisfy this requirement
 and only partially works.
  </p> 
  <p>
 We look at a drawn K-Map and visually decide that squares are adjacent or not.
 The improved definition of the K-Map gives a computer program an easy test for determining if two squares
 are adjacent, or measuring the degree of separation, by counting the number of different bits.
  </p> 
  <h2>So K-maps seem trivial if the maximum bits on an axis is two!</h2>
    <p>
 A bit pattern of any length can be thought of as being in a K-Map that has a 1-bit axis for each bit position.
 It may be hard to draw, but can be manipulated by a computer.
   </p>
<p>
 I will use the term <i>square</i> to indicate a single bit pattern on a K-Map.
 On a K-Map, groups of squares can be formed that have 2<sup>n</sup> squares, where n is one or greater.
 It seems natural to refer to a group of squares as a rectangle or square,
 but because of the dual use of the word square, and the implied two dimensions, I will instead use the word <i>region</i>. 
</p>
  <p>
 A K-Map region can be represented to any number of bits, using the characters 0, 1, and X, where X indicates a bit position that can be zero or one.
    </p>
 <p>
 Using a 2x2 K-Map for learning concepts, you can find algorithms for union, intersection, subtraction and complement for any number of bits.
 Union, intersection, subtraction and complement algorithms can also be found for operating on lists of regions.
 
   </p>
 <p>
 I will use the symbol "+" for the OR operation, "&amp;" for the AND operation,
 "^" for the XOR operation, and "~" for the NOT or Complement operation.
 The XOR operation is bitwise, the other operations may be bitwise operations or set operations, depending on the context.
   </p>
   <p>
 One way of representing a region in a computer is by taking any two bit patterns (bp1, bp2) and forming a high-bit and a low-bit pattern,
 where the high-bit pattern has the maximum number of one bits and the low-bit pattern has the
 minimum number of one bits. The high-bit pattern is equal to (bp1 + bp2).
 The low-bit pattern is equal to (bp1 &amp; bp2).
 A region can be formed by one bit pattern, the high and low bit patterns will be equal.
   </p> 
        <p>Interpretation of region high and low bits:</p>
      <table class="indent1">
           <tr>
                <th></th>
                <th>High Bit</th>
                <th>Low Bit</th>
                <th>Region Bit</th>
           </tr>
           <tr style="text-align:center;">
                <th></th>
                <td>0</td>
                <td>0</td>
                <td>0</td>
           </tr>
           <tr style="text-align:center;">
                <th></th>
                <td>0</td>
                <td>1</td>
                <td>not possible</td>
           </tr>
           <tr style="text-align:center;">
                <th></th>
                <td>1</td>
                <td>1</td>
                <td>1</td>
           </tr>
           <tr style="text-align:center;">
                <th></th>
                <td>1</td>
                <td>0</td>
                <td>X</td>
           </tr>
        </table>
   <p>
 For efficiency, you want to avoid scanning a bit pattern bit-by-bit.
 Operations can be done on more than one bit at a time by doing operations on an array of unsigned integers.
 After some operations, validation tests can produce a bit pattern that can be efficiently checked for all integers being equal to zero,
     or all integers equal to the maximum value.
   </p>
   <p>
 For some operations, the
  <a href="http://www-graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan">Count Bits Algorithm</a>
 can be used to count the number of one bits in an integer.
 The Count Bits Algorithm goes through one cycle for each bit that is set to one, no cycles for
        bits that are set to zero.
    </p>
   <p>
 I will represent a region as a list of bit patterns, high first, like X01X = (1011, 0010), or 0101 = (0101, 0101).
    </p>
   <h3>Calculating a Region X-mask and non-X-mask</h3>
 <p>
 The X-mask for a region can be calculated by using: mask = high-bits ^ low-bits.
 </p>
 <p class="indent1">
 Given that 0X1X = (0111, 0010),
 </p>
 <p class="indent1">
 The X-mask of 0X1X = 0111 ^ 0010 = 0101.
 </p>
 <p>
 The non-X-mask is the complement of the X-mask.
 </p>
 <p class="indent1">
 The non-X-mask of 0X1X = ~0101 = 1010.
 </p>
   <h3>Calculating a mask of different bits between two regions</h3>
 <p>
 To calculate a mask of corresponding bits that are 1/0 or 0/1 between two regions,
 use: mask = (r1.high-bits ^ r2.high-bits) &amp; (r1.low-bits ^ r2.low-bits).
 </p>
 <p class="indent1">
 Given 0X1X = (0111, 0010) and 110X = (1101, 1100).
 </p>
 <p class="indent1">
 The different bits mask of 0X1X and 110X = (0111 ^ 1101) &amp; (0010 ^ 1100) = 1010 &amp; 1110 = 1010.
 </p>
   <h3>Intersecting Regions</h3>
  <p>
 If two regions have no corresponding bits that are 0/1 or 1/0, they intersect.
 To find the intersection of two regions, simply translate corresponding X/0 and 0/X bits to 0,
 translate corresponding X/1 and 1/X bits to 1.
 Other equal, corresponding, bits will be the same value in the result.
  </p>
 <table class="indent1">
 <caption>0XX1 &amp; X11X = 0111 (7)</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td class="bgg">1</td>
  <td class="bgg">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgg">5</td>
  <td class="bgy">7</td>
  <td class="bgr">6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td>D</td>
  <td class="bgr">F</td>
  <td class="bgr">E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td>9</td>
  <td>B</td>
  <td>A</td>
    </tr>
 </table>
 <p>
 Two regions intersect if their different bits mask = all zeros.
        </p>
 <p>
 The intersection region is given by (r1.high-bits &amp; r2.high-bits, r1.low-bits + r2.low-bits).
        </p>
      <p class="indent1">
        Given 0XX1 = (0111, 0001) and X11X = (1111, 0110).
        </p>
        <p class="indent1">
 The intersection of 0XX1 and X11X = (0111 &amp; 1111, 0001 + 0110) = (0111, 0111) = 7.
        </p>
   <h3>Adjacent Regions</h3>
  <p>
 If two regions have exactly one corresponding bit position that is 0/1 or 1/0, they are adjacent.
  </p>
 <table class="indent1">
 <caption>1100, 0XX1, 1X1X</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td class="bgg">1</td>
  <td class="bgg">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgg">5</td>
  <td class="bgg">7</td>
  <td>6</td>
    </tr>
    <tr>
  <th>11</th>
  <td class="bgy">C</td>
  <td>D</td>
  <td class="bgr">F</td>
  <td class="bgr">E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td>9</td>
  <td class="bgr">B</td>
  <td class="bgr">A</td>
    </tr>
 </table>
 <p class="indent1">
 The regions 0XX1 and 1X1X are different by one bit, the left-most, and are adjacent.
        </p>
 <p class="indent1">
 The regions C (1100) and 0XX1 are different by more than one bit, the left-most and the right-most, and are not adjacent.
        </p>
   <p class="indent1">
 Given a mask that is an array of integers, if only one integer is greater than zero, the mask has one bit set to one if: int &amp; (int - 1) = 0 (adapted from the  <a href="http://www-graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan">Count Bits Algorithm</a>).
   </p>

  <h3>The Union of two Regions</h3>
  <p>
 Assume that you have two regions, 0XX1 and 1XX1, and all squares in the regions are known to be similar.
 If the regions are adjacent and have corresponding X bits, they can be combined.
 The one different bit becomes an X in the result.
 Other equal, corresponding, bits will be the same value in the result.
 In this case the result would be XXX1.
  </p>
 <table class="indent1">
 <caption>0XX1 + 1XX1 = XXX1</caption>
    <tr>
    <th>
 <table>
 <caption>0XX1, 1XX1</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td class="bgg">1</td>
  <td class="bgg">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgg">5</td>
  <td class="bgg">7</td>
  <td>6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td class="bgr">D</td>
  <td class="bgr">F</td>
  <td>E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td class="bgr">9</td>
  <td class="bgr">B</td>
  <td>A</td>
    </tr>
 </table>
 </th>
    <th>
 <table class="indent1">
 <caption>XXX1</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td class="bgy">1</td>
  <td class="bgy">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgy">5</td>
  <td class="bgy">7</td>
  <td>6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td class="bgy">D</td>
  <td class="bgy">F</td>
  <td>E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td class="bgy">9</td>
  <td class="bgy">B</td>
  <td>A</td>
    </tr>
 </table>
 </th>
 </tr>
    </table> 

  <p>
        To implement this:
   </p>
   <p class="indent1">
    Check that the regions are adjacent.
   </p>
   <p class="indent1">
    Check that the regions have equal X-masks.
   </p>
   <p class="indent1">
 The union of two regions (r1, r2)
        is given by (r1.high-bits + r2.high-bits, r1.low-bits &amp; r2.low-bits).
  </p>
   <p class="indent2">
 Given 0XX1 = (0111, 0001) and 1XX1 = (1111, 1001).
  </p>
   <p class="indent2">
 The Union of 0XX1 and 1XX1 = (0111 + 1111, 0001 &amp; 1001) = (1111, 0001) = XXX1.
  </p>
  <p>
 The union of 0X01 and X111 is the list (0X01, X111), since their X bits do not correspond.
 The list means "0X01 or X111".
  </p>
   <h3>Subtraction</h3>
  <p>
 If the two regions do not intersect, the answer is the minuend.
  </p>
  <p>
 Otherwise, look at each corresponding bit of the minuend and subtrahend.  Wherever you see an X in the
 minuend and 1 or 0 in the subtrahend, copy the minuend, but the corresponding
 X bit becomes <i>the opposite</i> of the bit in the subtrahend.
  </p>
  <p>
 So 1XX0 minus X01X = (11X0, 1X00).
  </p>
  <p>
 To implement this:
   </p>
   <p class="indent1">
   The bits to work on = r1.X-mask &amp; r2.Non-X-mask = 0110 &amp; 0110 = 0110.
  </p>
  <p class="indent1">
     A <i>Split-Bits</i> algorithm, to isolate each bit in a bit mask, e.g. producing (0100, 0010) from 0110 (adapted from the  <a href="http://www-graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan">Count Bits Algorithm</a>):
  </p>
  <p class="indent2">
      while (val > 0)<br />
      {
  </p>
  <p class="indent3">
          minus1 = val - 1; <br />              
          valLess1 = val &amp; minus1 &nbsp;&nbsp;&nbsp; // remove one bit from val, put into valLess1 <br />
          oneBit = val ^ valLess1; &nbsp;&nbsp;&nbsp; // isolate the removed bit <br />
   // Here, store oneBit into a new Bits object, add the Bits object to a BitsList object<br />
          val = valLess1;
  </p>
  <p class="indent2">
       }
  </p>
   <p class="indent1">
   For each isolated bit from the X/Non-X bit mask:
  </p>
 <p class="indent2">
  The subtrahend high and low bit for the bit position will be both one or both zero.<br />
  The minuend high-bit value for the bit position will be one and the low bit value will be zero.<br />
 </p>
 <p class="indent2">
  Calculate the isolated-bit &amp; the subtrahend.high-bits (or you can use subtrahend.low-bits).
 </p>
 <p class="indent2">
  If the result is non-zero, the bit value of the subtrahend is one, calculate a new
        region (r2) using the minuend, with that bit set to zero:<br />
  r2.high-bits = minuend.high-bits ^ isolated-bit, r2.low-bits = minuend.low-bits.
 </p>
 <p class="indent2">
 If the result is zero, the bit value of the subtrahend is zero, calculate a new
        region (r2) using the minuend, with that bit set to one:<br />
 r2.high-bits = minuend.high-bits, r2.low-bits = minuend.low-bits ^ isolated-bit.
 </p>
   <h3>Complement</h3>
   <p>
 Subtract the region from the Largest Possible Region.
   </p>
   <p>
 So ~101X = XXXX - 101X = (0XXX, X1XX, XX0X).
   </p>
   <h3>Testing if a region is equal to, or a subset of, another region</h3>
  <p>
        Two regions are equal if their corresponding bit masks are equal.
   </p>
   <p>
        A region is a subset of a second region is it is equal to its intersection with the second region.
   </p>
    <h3>Calculating the union of two region lists</h3>
 <p>
 Add the regions of both lists to a new list, discarding duplicate and subset regions.
 </p>
 <p>
 Simplification, like 1XXX + 0XXX = XXXX, is not done.
 </p>
    <h3>Calculating the intersection of two region lists</h3>
 <p>
 Intersect each possible pair of regions from the two lists, then form a list with the union of the results.
 </p>
        <h3>Adjacent parts of adjacent regions</h3>
        <p>
        Adjacent regions, without all X bits corresponding, have an adjacent part that can be calculated.
        </p>
        <table class="indent1">
        <caption>1X0X, X110</caption>
           <tr>
                <th></th>
                <th>00</th>
                <th>01</th>
                <th>11</th>
                <th>10</th>
           </tr>
           <tr>
                <th>00</th>
                <td>0</td>
                <td>1</td>
                <td>3</td>
                <td>2</td>
           </tr>
           <tr>
                <th>01</th>
                <td>4</td>
                <td>5</td>
                <td>7</td>
                <td class="bgg2">6</td>
           </tr>
           <tr>
                <th>11</th>
                <td class="bgr">C</td>
                <td class="bgr2">D</td>
                <td>F</td>
                <td class="bgg">E</td>
           </tr>
           <tr>
                <th>10</th>
                <td class="bgr2">8</td>
                <td class="bgr2">9</td>
                <td>B</td>
                <td>A</td>
           </tr>
        </table>
            <p>
        To calculate the adjacent part of 1X0X and X110, start with the intersection logic, even though they do not intersect.
        </p>
	<p>1X0X = (1101, 1000)</p>
	<p>X110 = (1110, 0110)</p>
	<p></p>
	<p>
	AND the high bits: 1101 & 1110 = 1100
	</p>
	<p>
	OR the low bits:   1000 + 0110 = 1110
	</p>
	<p>
	Now make a region from the results, 1100, 1110.
	</p>
	<p>
	OR the results:  1100 + 1110 = 1110 (high mask)
	</p>
	<p>
	AND the results: 1100 & 1110 = 1100 (low mask)
	</p>
	<p>
	(1110, 1100) = 11X0 (C, E)
	</p>
    <h2>Sparse Karnaugh Maps</h2>
    <p>
     In class we learn how to use K-Maps starting with all the squares filled in.
 It occurred to me that a K-Map without all squares filled in might be interesting.
   </p>
 <p>
 How would you make a best guess at the logic of a Sparse K-Map?
 </p>
 <p>
 If you could choose to get information about an additional square, which square would be the best choice?
 I assume that there is at least one method that is better than a random choice.
    </p>
    <p>
 I will use the term <i>sample</i> to indicate an activity that results in some value for a square
 to allow comparing it to other squares to determine similarity or dissimilarity.
   </p>
  <h3>The Optimistic Union</h3>
  <p>
 I would like to define a second kind of union that can be thought of as
 "Barring evidence to the contrary, the union could be true".
 This type of union is between two or more squares and ignores the requirements of the union,
 given above, except that the squares be considered to be similar.
 Corresponding bits that are 1/0, or 0/1 will be X in the result. 
 Other equal, corresponding, bits will be the same value in the result.
 Evidence to the contrary would be two dissimilar squares in the result region.
    I will use "++" as an operator to denote an Optimistic Union.
  </p>
 <p class="indent1">
 0011 ++ 0101 ++ 1111 = XXX1
   </p>
    <p class="indent1">
 <table>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td>0</td>
  <td class="bgg2">1</td>
  <td class="bgg">3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td>4</td>
  <td class="bgg">5</td>
  <td class="bgg2">7</td>
  <td>6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td class="bgg2">D</td>
  <td class="bgg">F</td>
  <td class="bgr">E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td class="bgg2">9</td>
  <td class="bgg2">B</td>
  <td>A</td>
    </tr>
 </table>
  </p>
   <p>
 Current personal computers handle data 64 bits at a time.
 With a K-Map of 64 bits, you can make some Optimistic Unions with a few hundred samples,
 or you can seek samples of all 2<sup>64</sup> (18,446,744,073,709,551,616) possible squares.
 At one sample per second, it would take 584,942,417,355 years to get every sample.
 Assuming the Universe is 20 Billion years old, that is 29 times the age of the Universe.
   </p>
 <p>
 The Optimistic Union is a necessary shortcut for understanding a large, sparse, Bitscape.
 You can get more samples and improve your Optimistic Unions, but you cannot get all possible samples.
 It is possible to get samples of all squares in a small region within the Bitscape,
 which might be thought of as proving something.
 </p>
 <p>
 The concept of a scientific theory being assumed to be true, until it is falsified, seems to imply an Optimistic Union.
 </p>
 <p>
 To implement this:
 </p>
<p class="indent1">
        Given similar squares, form a region.  In this case:
        </p>
        <p class="indent2">
        Region high-bits = 1 + 3 + F = F
        </p>
        <p class="indent2">
        Region low-bits = 1 &amp; 3 &amp; F = 1
        </p>
        <p class="indent1">
        Check that there is no dissimilar pair of squares in the region.
        </p>
 <p class="indent1">
 Any new sample for a square that is in the region must cause a revalidation of the region.
 </p>
 <h4>Preventing an Optimistic Union</h4>
        <p>
        If square E, above, is dissimilar to square F, no Optimistic Union can contain both squares.
        </p>
        <p>
        So no Optimistic Union can be a superset of F + E = 111X.
        </p>
        <p>
        The bit pattern of square E is different from square F in the last position, with a value of 0.
        </p>
        <p>
        Any square in the region XXX0 making an Optimistic Union with square F would form at least an X in the last position and be a superset of 111X.
        </p>
        <p>
        So it can be said that square E prevents an Optimistic Union of F with any square in XXX0.
        </p>
  <h3>Contradictory intersections</h3>
        <p>
        Intersections of sparse regions may imply a contradiction and need to be sampled.
        </p>
   <h3>Confirming an Optimistic Union</h3>
    <p>
 In a solved K-Map, of the regions that are completely overlapped by other regions, any one of them, sometimes more, can be discarded.
  </p>
  <p>
    Those regions that cannot be discarded, that therefore <i>define</i> the solution, have at least one square that is not overlapped by any other region (before discarding regions), therefore at least one square that is only in one region.
    </p>
    <p>
 What causes a square to be only in one region?
            </p>
        <p class="indent1">
 Consider a square, s1, that is only in one region of a completed solution.
            </p>
        <p class="indent1">
 For each non-X bit position of the region, there will be a square, s2, outside the region
 that is adjacent to s1.
            </p>
        <p class="indent2">
          s2 can be calculated by: non-X bit position mask ^ s1.
    </p>
        <p class="indent1">
 If s1 is similar to s2, then the two squares form a region and s1 is in two regions.
  </p>
  <p>
    <i>For a square that is only in one region, it must be dissimilar to all adjacent squares outside of the region</i>.
    </p>
    <p>
      <i>This allows us to predict that a square is in only one region, therefore a defining region, without having a complete solution!</i>
    </p>
    <p class="indent1">
        If the prediction is wrong, the square is either in multiple subregions of the predicted region, or there is a dissimilar, adjacent, square within the predicted region.
    </p>
   <h4>Calculating possible regions using dissimilar pairs of squares</h4>
        <p>
        With a pair of dissimilar squares, you know that there can be no region of similar squares that contains both squares.
  </p>
   <p>
        So each square will be in at least one of the regions that the other square is not in.     
        </p>
        <p>
        <i>Given two dissimilar squares (s1, s2), Possible Regions &#8838; ~s1 + ~s2</i>
        </p>
        <p class="indent1">
        For 4 and E within XXXX, ~4 = (1XXX, X0XX, XX1X, XXX1),  ~E = (0XXX, X0XX, XX0X, XXX1).<br />
        ~4 + ~E = (0XXX, XX0X, 1XXX, XX1X, XXX1, X0XX), 6 regions, no squares are only in one region.
        </p>
        <p>
        Finding adjacent, dissimilar, squares decreases the number of possible regions produced by the calculation, and increases the number of squares that are only in one region.
        </p>
        <p class="indent1">
        For C and E within XXXX, ~C = (0XXX, X0XX, XX1X, XXX1),  ~E = (0XXX, X0XX, XX0X, XXX1).<br />
        ~C + ~E = (XX1X, XXX1, 0XXX, X0XX, XX0X), 5 regions, E only in XX1X, C only in XX0X.
        </p>
        <p>
          If you have two pairs of dissimilar squares, (s1, s2) and (s3, s4), it seems that PR &#8838; ~s1 + ~s2 <i>and</i> PR &#8838; ~s3 + ~s4.
        </p>
        <p>
        So you can infer that PR &#8838; (~s1 + ~s2) &amp; (~s3 + ~s4).
        </p>
        <p class="indent1">
        (~5 + ~1) &amp; (~F + ~E) = (X0XX, XXX0, X10X, 1X0X, 0X1X, 01XX, XX11, 1XX1, X1X1), 9 regions, 1 only in X0XX, E only in XXX0.
        </p>
        <p>
        A square with two adjacent, dissimilar, squares, is better than two pairs of adjacent, dissimilar, squares that do not have a square in common. Not only are the results better, the number of squares that need to be sampled is fewer.
        </p>
        <p class="indent1">
        (~5 + ~7) &amp; (~5 + ~D) = ~5 + (~7 &amp; ~D) = (1XXX, XX1X, X0XX, XXX0, 0X0X), 5 regions, 7 only in XX1X, D only in 1XXX, 5 only in 0X0X.
        </p>
      <p>
       Intersecting the implied regions from many disparate dissimilar pair calculations can produce an unwieldy number of possible regions.
     </p>
         <p class="indent1">
        If the dissimilar pairs of squares are near each other, the number of regions can be managable.
        </p>
         <p>If you are only interested in the region that contains square 5, given dissimilar squares (D, 7), efficiency can be gained by using only that part of the complements of squares D and 7 that contain square 5.
        </p>
        <p class="indent1">
        Where square D or 7 have a bit that is different from square 5, there will be a complement region that contains square 5.
        </p>
        <p class="indent1">
        Square D is different from square 5 in the first bit position, with a value of 1, giving complement region 0XXX.
        </p>
        <p class="indent1">
        Square 7 is different from square 5 in the third bit position, with a value of 1, giving complement region XX0X.
        </p>
        <p class="indent1">
        0XXX &amp; XX0X = 0X0X.
        </p>
  <h4>Implementation</h4>
    <p>
 A region formed by an Optimistic Union can be thought of as being confirmed as a defining part of a solution, if it has:
    </p>
    <ul class="indent1">
    <li>
    <p>
 A sampled square, s1.
    </p>
    </li>
    <li>
    <p>
 All squares adjacent to s1, outside of the region, are dissimilar to s1.
    </p>
    <p class="indent1">
 To identify these squares, use the Split-Bits algorithm on the region non-X-mask, then XOR each isolated bit with s1.
    </p>
    </li>
    <li>
    <p>
 Square s1 has a far, similar, square, s2, within the region.  s2 = s1 ^ region.X-mask.
      It takes a minimum of two squares to define a region.
    </p>
    </li>
    <li>
    <p>
 No two squares within the region are dissimilar.
    </p>
    </li>
    </ul>
    <p class="indent2">
 In the K-Map, below, square 5 cannot form an Optimistic Union with any square in XX1X without including the
 dissimilar square 7.  Square 5 cannot form an Optimistic Union with any square in 1XXX without including the
 dissimilar square D.
    </p>
 <table class="indent2">
 <caption>0X0X Confirmed</caption>
    <tr>
  <th></th>
  <th>00</th>
  <th>01</th>
  <th>11</th>
  <th>10</th>
    </tr>
    <tr>
  <th>00</th>
  <td class="bgg">0</td>
  <td class="bgg2">1</td>
  <td>3</td>
  <td>2</td>
    </tr>
    <tr>
  <th>01</th>
  <td class="bgg2">4</td>
  <td class="bgg"><b>5</b></td>
  <td class="bgr"><b>7</b></td>
  <td>6</td>
    </tr>
    <tr>
  <th>11</th>
  <td>C</td>
  <td class="bgr">D</td>
  <td>F</td>
  <td>E</td>
    </tr>
    <tr>
  <th>10</th>
  <td>8</td>
  <td>9</td>
  <td>B</td>
  <td>A</td>
    </tr>
 </table> 
    <p class="indent2">
    We now know that square 5 is only in one region and what that region is.
    </p>
   <p class="indent2">
        It is possible that the square is really in one or more subset regions of the apparent region.
        If the apparent region contains no dissimilar squares, it is valid &quot;to the best of our knowledge&quot;.
    </p>
    <p class="indent1">
 Checking that squares adjacent to square 5, within the region, are similar to square 5, in this case 1 and 4, is an extra check for the validity of the region.
    </p>
     <p class="indent2">
        To identify these squares, use the Split-Bits algorithm on the region X-mask, then XOR each isolated bit with s1.
    </p>
     <p class="indent1">
        This seems like a lot of squares are sampled! 
   </p> 
  <p class="indent2">
    It is more efficient with larger regions since the number of squares in a region goes up by 2<sup>number of X-bit positions</sup>, while the number of squares to sample is proportional to the number of bit positions.
    </p>
  <p class="indent2">
    <i>Knowing is better than guessing</i>.  Having a defining region allows you to know.  Having an approximation to a defining region, consisting of a random assortment of overlapping non-falsified regions, only allows you to guess.
    </p>
  <p class="indent2">
        Storing a defining region takes less memory than storing its less useful approximation.
    </p>
    <p>
 With multiple confirmed regions, there is the opportunity/problem of minimizing the number of squares needed to define the regions.
    </p>
  </div>
 <div id="learning">
    <h2>Automated Learning and Experimentation</h2>
    <p>
 There have been a few times when it seemed like I could sense what was changing in my mind when
 solving a problem.  This could be called "connecting the dots" or "changing the bits".  These
 infrequent perceptions are the inspiration for much of this web page.
    </p>
    <p>
 When you are trying to solve a problem, you usually do not have all possible samples.
 You make a guess, and you try to get more samples to confirm your guess.
 When you try to get more samples, you usually choose them in some way, rather
 than at random.
    </p>
    <p>
 Consider the old game of Battleship.
 You randomly hit some of your opponents squares until you hit something.
 Then you explore around the successful hit to outline the shape of the ship.
 Your last one or two hits are calculated and successful.
 You win the game without hitting all the squares.
    </p>
   <p>
 Calculating regions from a given set of samples can be considered to be experiential aggregation, allowing you to guess.
   </p>
 <p>
 Seeking samples to calculate defining regions can be considered to be learning, allowing you to know.
   </p>
   <p class="indent1">
  This depends on some previous experiential aggregation to suggest possible defining regions.
   </p>
   <p class="indent2">
 A large amount of experiential aggregation may allow a defining region to simply become apparent.
   </p>
   <p>
 Noticing that the regions do not explain everything, due to gaps not covered by the 
 regions, or regions having contradictory intersections, can cause the seeking 
 of more samples, which can be considered to be experimentation.
 </p>
    <h4>Implementation</h4>
     <p>
        Keep an array of integers representing a single square in a K-Map, the "current state".
        </p>
        <p>
        Keep a list of actions the program can execute to change the state, and store the implied logic of the changes experienced.
        </p>
        <p class="indent1">
        Some functions can be run on the actions concurrently, then aggregate the results.
        </p>
        <p class="indent2">
        Get sampling needs to improve the understanding of the logic of the state changes.
        </p>
        <p class="indent2">
        Get possible forward-chaining steps.
        </p>
        <p class="indent2">
        Get possible backward-chaining steps.
        </p>
        <p class="indent1">
        This is fortuitous, since these are major functions that are frequently called.  There are no shared resources to lock,
          no need to synchronize threads.
        </p>
        <p>
        For each action:
        </p>
         <p>
        Keep a list of superset non-falsified regions of similar sampled squares.
        </p>
     <p class="indent1">
        A newly sampled square may invalidate some regions.
        </p>
        <p class="indent1">
        A newly sampled square, and squares from invalidated regions, can be compared to other squares to form new regions.
        </p>
        <p>
        Identify and resolve contradictory intersections.
        </p>
     <p class="indent1">
        Contradictory intersections can be identified by:
        </p>
        <p class="indent2">
        Reviewing region intersections of newly created regions.<br />
        Predicting a step in a plan.<br />
        An unsolicited experience.
        </p>
        <p>
        Use squares that appear to be in only one region to confirm regions.
        </p>
        <p class="indent1">
        A square used to confirm a region may become overlapped by later processing, causing a region to be unconfirmed.
        </p>
      <p class="indent1">
        If an external adjacent square turns out to be similar instead of dissimilar:
        </p>
        <p class="indent2">
          Check if the region and square can form a region, doubling the original region size.
       </p>
        <p class="indent2">
        Otherwise, form a new region from the two simmilar squares.
        </p>
        <p>
     If the result of the current state cannot be predicted, sample it.
     </p>
     <p class="indent1">
        The first samples of this kind can be used to form bootstrap regions that can be used, with some errors,
        to change the current state to a state needed by the logic adove.
     </p>
     <p class="indent1">
        The effect of this is kind of random, so it is more effective to try sampling squares non-randomly, above, before this.
     </p>
   </div>
   <div id="rules">
    <h2>State-Change Rules</h2>
    <p> 
 State-Change Rules attempt to make sense of how a state or region changes when an activity or action can be executed that may result in a state change.
 State-Change Rules are a working point-in-time understanding of logic based on a limited number of recent samples.
 State-Change Rules can be vexing, but they simply depend on something being predictable.
    </p>
    <h3>Single bit State-Change Rules</h3>
    <p> 
 Assuming a state of one bit, and a time or activity after which the state is sampled a second time, a rule
 describing the two samples can be generated.
 The rule may be one of the following four possibilities:
    </p>
    <ul class="indent1">
 <li>0 &#8594; 0</li>
 <li>0 &#8594; 1</li>
 <li>1 &#8594; 1</li>
 <li>1 &#8594; 0</li>
    </ul>
    <p>
 The left bit can be referred to as the initial state, the right bit can be referred to as the
 result state.
    </p>
    <p>
 On the third sample, a rule can be generated from the second and third samples.
 Assuming the samples are 0 &#8594; 1 &#8594; 0, we have rule 0 &#8594; 1 and 
 rule 1 &#8594; 0.
    </p>
    <p>
 There are ten possible ways to combine two rules:
    </p>
    <ul class="indent1">
 <li>0 &#8594; 0, 0 &#8594; 0 = 0 &#8594; 0</li>
 <li>0 &#8594; 1, 0 &#8594; 1 = 0 &#8594; 1</li>
 <li>1 &#8594; 1, 1 &#8594; 1 = 1 &#8594; 1</li>
 <li>1 &#8594; 0, 1 &#8594; 0 = 1 &#8594; 0</li>
 <li>0 &#8594; 0, 0 &#8594; 1 = 0 &#8594; X (disallowed)</li>
 <li>0 &#8594; 0, 1 &#8594; 1 = X &#8594; X</li>
 <li>0 &#8594; 0, 1 &#8594; 0 = X &#8594; 0</li>
 <li>0 &#8594; 1, 1 &#8594; 1 = X &#8594; 1</li>
 <li>0 &#8594; 1, 1 &#8594; 0 = X &#8594; <span class="not">X</span></li>
 <li>1 &#8594; 1, 1 &#8594; 0 = 1 &#8594; X (disallowed)</li>
    </ul>
    <p>
 Most of the combinations are by similar changes (or lack of change) and/or similar results.
    </p>
    <p>
 The combinations that result in 0&#8594;X and 1&#8594;X, having dissimilar changes, dissimilar results and no predictive value, are disallowed.
    </p>
      <p>
        The bit-changes 0&#8594;0 and 0&#8594;1 are a <i>dissimilarity</i>,
        preventing the union of rules  with these characteristics.
    </p>
    <p>
        The bit-changes 1&#8594;0 and 1&#8594;1 is a second <i>dissimilarity</i>,
        preventing the union of rules with these characteristics.
    </p>
    <p>
 Combinations of more than two different 1-bit rules will always combine to one of 0&#8594;X and/or 1&#8594;X, and are disallowed.
    </p>
    <p>
 The combined rules on the right side of the equals sign, above, can start and end with 0, 1 or X.
      So <i>the initial and result states of the rules can describe K-Map squares and regions</i>.  
    </p>
      <p>
        Dissimilar squares can be used to discover defining regions of State-Change Rules.
    </p>
    <h3>Multiple bit State-Change Rules</h3>
    <p>
 If you have a four-bit state and sample it, the result state can be used to construct a four-bit State-Change rule.
    </p>
    <p>
 State 0010, with a result state of 0100 produces the State-Change rule: (0&#8594;0, 0&#8594;1, 1&#8594;0, 0&#8594;0).
    </p>
    <p>
 State 0101, with a result state of 0001 produces the State-Change rule: (0&#8594;0, 1&#8594;0, 0&#8594;0, 1&#8594;1).
    </p>
    <p>
 State 0010 and 0101 can form an Optimistic Union of 0XXX.
    </p>
    <p>
 The State-Change rules of State 0010 and 0101 can also be combined:
 </p>
 <p class="indent1">
 (0&#8594;0, 0&#8594;1, 1&#8594;0, 0&#8594;0)<br />
 (0&#8594;0, 1&#8594;0, 0&#8594;0, 1&#8594;1)<br />
 ------------------------------------<br />
 (0&#8594;0, X&#8594;<span class="not">X</span>, X&#8594;0, X&#8594;X)
    </p>
    <p>
 The state 0110 is within the above union of 0XXX.
    </p>
    <p>
 State 0110, with a result state of 0100 produces the State-Change rule: (0&#8594;0, 1&#8594;1, 1&#8594;0, 0&#8594;0).
    </p>
    <p>
     In the State-Change rules for states 0010 and 0101, above, in the second position from the left, there are two bit changes, 0&#8594;1 and 1&#8594;0.
    </p>
    <p>
 The State-Change rule for state 0110 adds a third kind of change in the second position, 1&#8594;1.
 The bit rules 1&#8594;1 and 1&#8594;0 invalidate the Optimistic Union. 
    </p>
    <h3>Implementation</h3>
   <p>
        One way to represent a State-Change Rule, is to keep masks for each of the four possible bit changes.
    </p>
    <p>
        Given a sample, i&#8594;r,
        form the rule as follows:
    </p>
    <p class="indent1">
        The 0&#8594;0 mask = ~i &amp; ~r
    </p>
    <p class="indent1">
        The 0&#8594;1 mask = ~i &amp; r
    </p>
    <p class="indent1">
        The 1&#8594;1 mask = i &amp; r
    </p>
    <p class="indent1">
        The 1&#8594;0 mask = i &amp; ~r
    </p>
     <p>
        Two rules are equal if their corresponding masks are equal.
    </p>
    <p>
        A union of two rules can be formed by calculating the union of corresponding masks.
    </p>
    <p class="indent1">
        A union combines bit-changes, so validate the result with:
    </p>
    <p class="indent2">
        1&#8594;0 mask &amp; 1&#8594;1 mask = all zeros.
    </p>
    <p class="indent2">
        0&#8594;0 mask &amp; 0&#8594;1 mask = all zeros.
    </p>
      <p class="indent2">
        Where these masks are non-zero, they identify a dissimilarity and can be useful.
    </p>
      <p class="indent2">
         If a rule with an initial region of 1X0X includes a 1&#8594;X bit in the second position,
        that indicates that 110X is invalid, while 101X may be valid.
    </p>
      <p>
        A rule is a subset of another rule if the corresponding masks are subsets.
    </p>
      <p>
        The initial region can be calculated with:
    </p>
    <p class="indent1">
      Region high-bits = <b>1</b>&#8594;1 mask + <b>1</b>&#8594;0 mask
     </p>
     <p class="indent1">
       Region low-bits = ~(<b>0</b>&#8594;0 mask + <b>0</b>&#8594;1 mask)
    </p>
    <p>
        An intersection of two rules can be formed by calculating the intersection of corresponding masks.
    </p>
   <p class="indent1">
        An intersection may lose bit-changes, so validate the result with:
    </p>
    <p class="indent2">
        0&#8594;0 mask + 0&#8594;1 mask + 1&#8594;1 mask + 1&#8594;0 mask = all ones.
        If not, the entire intersection is dissimilar.
    </p>
     <p class="indent2">
     The initial region of the result is equal to the intersection of the inital regions of the two rules.
       If not, the region of the result is the similar part of the intersection.
     </p>
    <p>
        The result region can be calculated with:
    </p>
    <p class="indent1">
      Region high-bits = 1&#8594;<b>1</b> mask + 0&#8594;<b>1</b> mask
     </p>
     <p class="indent1">
       Region low-bits = ~(0&#8594;<b>0</b> mask + 1&#8594;<b>0</b> mask)
    </p>     
    <p>
        Forward-Chaining
    </p>
    <p class="indent1">
       For a region (rg) that intersects the initial region of a rule, restrict the rule to that intersection by filtering similar initial bits:
    </p>
    <p class="indent2">
      0&#8594;0 restricted = <b>0</b>&#8594;0 &amp; ~rg.<b>low-bits</b>
    </p>
    <p class="indent2">
      0&#8594;1 restricted = <b>0</b>&#8594;1 &amp; ~rg.<b>low-bits</b>
    </p>
    <p class="indent2">
      1&#8594;1 restricted = <b>1</b>&#8594;1 &amp; rg.<b>high-bits</b>
    </p>
    <p class="indent2">
      1&#8594;0 restricted = <b>1</b>&#8594;0 &amp; rg.<b>high-bits</b>
    </p>
    <p class="indent1">
        Then calculate the result region of the restricted rule.
    </p>
    <p>
        Backward-Chaining
    </p>
    <p class="indent1">
         For a region (rg) that intersects the result region of a rule, restrict the rule to that intersection by filtering similar result bits:
    </p>
    <p class="indent2">
      0&#8594;0 restricted = 0&#8594;<b>0</b> &amp; ~rg.<b>low-bits</b>
    </p>
    <p class="indent2">
      0&#8594;1 restricted = 0&#8594;<b>1</b> &amp; rg.<b>high-bits</b>
    </p>
    <p class="indent2">
      1&#8594;1 restricted = 1&#8594;<b>1</b> &amp; rg.<b>high-bits</b>
    </p>
    <p class="indent2">
      1&#8594;0 restricted = 1&#8594;<b>0</b> &amp; ~rg.<b>low-bits</b>
    </p>
    <p class="indent1">
        Then calculate the initial region of the restricted rule.
    </p>
    <h3>Contradictory Intersections</h3>
    <p>
 In the K-Map, below, squares 1 and F form the region XXX1.  Squares C and F form the region 11XX.
 The intersection of the two regions is 11X1, which contains D (no samples yet) and F.
    </p>
    <p>
 If the third bit from the left in square C has a State-Change Rule of 0&#8594;1 and the corresponding bit in the square F has a State-Change Rule of 1&#8594;0,
 the combination produces the State-Change Rule X&#8594;<span class="not">X</span>.
    </p>
    <p>
 If the third bit from the left in square 1 has a State-Change Rule of 0&#8594;0 and the corresponding bit in the square F has a State-Change Rule of 1&#8594;0,
 the combination produces the State-Change Rule X&#8594;0.
    </p>
    <p>
 Squares 1 and C cannot be combined because the third bit from the left would form a State-Change Rule
 of 0&#8594;X, which is disallowed.
    </p>
    <p>
 The corresponding bit in square D is 0.  The Optimistic Union of (1, F) predicts that when square D is sampled, the corresponding result bit will be 0.
 The Optimistic Union of (C, F) predicts that the corresponding result bit will be 1.
    </p>
    <p>
 A contradictory intersection has been found at square D, and a sample of that square should be taken.
    </p>
     <table class="indent1">
        <caption>XXX1 and 11XX</caption>
           <tr>
                <th></th>
                <th>00</th>
                <th>01</th>
                <th>11</th>
                <th>10</th>
           </tr>
           <tr>
                <th>00</th>
                <td>0</td>
                <td class="bgg">1</td>
                <td class="bgg2">3</td>
                <td>2</td>
           </tr>
           <tr>
                <th>01</th>
                <td>4</td>
                <td class="bgg2">5</td>
                <td class="bgg2">7</td>
                <td>6</td>
           </tr>
           <tr>
                <th>11</th>
                <td class="bgg">C</td>
                <td class="bgr2">D</td>
                <td class="bgg">F</td>
                <td class="bgg2">E</td>
           </tr>
           <tr>
                <th>10</th>
                <td>8</td>
                <td class="bgg2">9</td>
                <td class="bgg2">B</td>
                <td>A</td>
           </tr>
        </table>
    <p>
 To implement this:
     </p>
     <p class="indent1">
 Intersect XXX1 and 11XX to get 11X1.<br />
 </p>
     <p class="indent1">
        Intersect the rules for the two regions.  If the intersection is valid, it will be
        expected to produce the same results by each of the two intersecting regions.  Calculate
        the initial region of the intersected rule (in this case F).
        </p>
        <p class="indent1">
        Subtract the intersected rule initial region, if any, from the larger region intersection.
        (in this case, 11X1 - F = D).  This region will be expected to have different results
        by the rules of the two intersecting regions.
        </p>
        <p class="indent1">
        Sample squares from a region predicted to have different results.
        </p> 
    <h3>Multiple Result States</h3>
    <p>
 Taking multiple samples of the same state can produce different results.
     </p>
    <p>
 I am tempted to say that a state that produces more than one result can simply be called unpredictable and combined with other such states
 to produce unpredictable regions.  These regions would be invalidated by an included state that is predictable. But I feel that simple patterns like
  (0, 1, 0, 1, 0) should be accommodated. 
    </p>
    <p>
 A pattern can be defined as a sequence of results that is seen at least twice in the result list.
    </p>
    <p>
 For a state that always produces the same result, a minimum of two samples will be needed.
    </p>
    <p>
For a state that always produces the same two results, alternating, a minimum of four samples will be needed.
    </p>
    <p>
 If a state has two different results that do not alternate, or more than two different results, the state with that result list can be marked as being unpredictable.
 There is always the possibility that continued sampling, with the oldest samples being dropped to conserve memory,
 could change a state between being predictable and unpredictable.
    </p>
     <p class="indent1">
    This is a third kind of <i>dissimilarity</i>, preventing the union of rules with these differing characteristics.
   </p>
     <p class="indent1">
   When a predictable region intersects an unpredictable region, the intersection region can be considered to be contradictory.
   </p>
   <p class="indent1">
   In the intersection region, sample a state until its predictability or unpredictability is determined.
   </p>
    <p>
 Combining the state with each result in a result pattern list creates a State-Change Rule list.  A union can be formed from two State-Change Rule lists, from different states.
 The union may be valid if, in a sequence that may start at different positions in the two lists, each make a valid union (no 0&#8594;X or 1&#8594;X bits).
    </p>
     <p>
    A state that exhibits two different results must necessarily, in aggregate, have some 0&#8594;X or 1&#8594;X bit positions.  These bit positions must be preserved in any union with another state, they cannot be replaced by an X&#8594;anything bit position.
</p>    
   <p class="indent1">
    This is a fourth kind of <i>dissimilarity</i>, preventing the union of rules with these differing characteristics.
   </p>
   <p>
        Two states that have not established a result pattern, and have not become unpredictable, may appear to be compatible, but it might be better to say that they are not-incompatible.
   </p>
     <p class="indent1">
        When first starting to accumulate samples, many samples must be taken using the current state, since rule-paths cannot be built without regions.
    </p>
     <p class="indent1">
        Sampling the current state and finding that it changes is crucial, but it is not conducive to resampling the state.
    </p>
     <p class="indent1">
        So the early regions must be formed from samples that are poorly sampled, but not-incompatible.
    </p>
     <p class="indent1">
        Using early regions to build rule-paths will often produce unexpected changes, but each unexpected change can be learned from.  Failure rates should decrease with more samples from both rule-path failures and rule-path successes.
    </p>
    <p>
        One state that has established a result pattern, or has become unpredictable, and one state that has not, can be said to be not-incompatible (more samples needed) or incompatible.
   </p>
    <p>
        Two states that have established a result pattern, or have become unpredictable, can be said to be compatible or incompatible.
   </p>
    <p>
        Two compatible states can form a region if there is no state between them that is incompatible with either state.
   </p>
     <p>
     If confirming a mutiple-result region, it is unnecessary to check squares that are external by virtue of aggregate 0&#8594;X or 1&#8594;X bit positions.
   </p>
  </div>
  <div id="combex">
    <h2>The Combinatorial Explosion, defeated!</h2>
    <p>
 Expert systems sometimes churn through millions of possible rule combinations
 to predict what rules can be used, and in what order, to reach a goal.
 Because of this, even supercomputers can get bogged down.
 There are always tricks to cut out some combinations, but they tend to be specific to the problem being solved.
 Regardless of the tricks used to make a given search faster,
 if the next search requires a few more rules, the computer will get bogged down again.
 It is hard to overstate the difficulty of this problem.
    </p>
    <p>
 The cause of the problem is that <i>the computer has no sense that using a rule will get it closer to its
 goal. Predicting the goal as the result of the last rule, in the most recent sequence of rules tried, is an unlikely surprise!</i>
 Discovering a rule combination that ends in the desired goal state is costly due to the huge number of useless combinations that have to be considered.
 Failure to discover a rule combination that ends in the desired goal state is even more costly, because it is not obvious when to stop the
 search.
    </p>
    <p>
 If you represent the current state and goal state as bit patterns (like squares on a K-Map),
 you can count the number of bits that are different between the two states and say they are that number of bits apart.
 </p>
 <p>
 <i>A rule that changes the current state in a way that reduces the
 number of bits different from the goal state can be understood to bring the current state closer to the goal state.</i>
 Decreasing the number of bits different from the goal state increases the probability that one rule is available that can change the current state to the goal state.
    </p>
     <p>
       A goal can be a range of states, represented by a region, where X bit positions are not important.
    </p>
        <p>
 This approach greatly decreases the effort required to find a combination of rules (rule-path) to attain a desired goal.
 A less obvious benefit is a timely failure, so that effort is not wasted to find a rule-path to an unreachable goal.
 </p>
    <p>
 Finding a rule-path can be challenging, or fail, if:
    </p>
 <ul class="indent1">
 <li>
     <p>
 There is an incomplete understanding of the logic (similar to real life).  The only possible predicted rule-path to a goal may
 traverse a gap that is not covered by an Optimistic Union.
 </p>
 </li>
 <li>
    <p>
 There are rules that change more than one bit at a time.
 Your current state may be one bit away from your goal state, but all the available rules change two bits at a time.
 Combinations of rules might have the effect of changing one bit.
        Finding such a combination may involve a Combinatorial Explosion, but once found, such a combination can be used any number of times.
 </p>
 </li>
 <li>
    <p>
 There are states or regions that you want to avoid to varying degrees.
 When driving a car, you do not want to depress the brake pedal and gas pedal at the same time, you may decide to drive around an obstacle instead of through it.
 The attraction of the goal, relative to the avoidance factor of the regions a rule-path traverses, may restrict the rule-path choice.
 </p>
 </li>
 <li>
     <p>
 There are regions that produce unpredictable results.  A rule-path prediction cannot be extended through an unpredictable region.
 </p>
 </li>
 <li>
 <p>
 There are regions that have more than one State-Change rule. You might need to run an action more than once to get the desired change for a state.
 If the rule changes other bits you may need to make and run a return-to-previous-state plan to rerun the action.
 </p>
 </li>
 </ul>
    <p>
 Using a rule-path can fail, if:
 </p>
 <ul class="indent1">
 <li>
    <p>
 There is an erroneous understanding of the logic (similar to real life).  An Optimistic Union might be too broad, so
 an unexpected result is encountered.
 </p>
 <p>
 An unexpected result would delete an Optimistic Union and form other Optimistic Unions,
 possibly with gaps and contradictory intersections.
 </p>
 </li>
 <li>
    <p>
 Something changes during the execution of a rule-path that requires recalculating the rule-path (similar to real life).
 </p>
 </li>
 </ul>
 <h3>Random Depth-First search</h3>
  <p>
   A depth-first search is used to avoid testing the large number of possibilities in a breadth-first search, but it may fail while a breadth-first
   search would succeed.
   If a depth-first search always chooses randomly from multiple equally likely paths, then each iteration of the search may be different.
   Then the depth-first search can be run multiple times until it succeeds, or until an arbitrary number of attempts, an arbitrary time duration, or some other limit, has been reached.
  </p>
    <h3>Rule-path searches</h3>
 <p>
 Given the avoid-list (011X, 1X01) and the following rules:
 </p>
 <p class="indent1">
 R1: (X&#8594;<span class="not">X</span>, X&#8594;X, X&#8594;X, X&#8594;X)<br /><br />
 R2: (X&#8594;X, X&#8594;<span class="not">X</span>, X&#8594;X, X&#8594;X)<br /><br />
 R3: (X&#8594;X, X&#8594;X, X&#8594;<span class="not">X</span>, X&#8594;X)<br /><br />
 R4: (X&#8594;X, X&#8594;X, X&#8594;X, X&#8594;<span class="not">X</span>)
 </p>
 <p>
 Find a rule-path from 0 to F.
 </p>
     <table class="indent1">
           <tr>
                <th></th>
                <th>00</th>
                <th>01</th>
                <th>11</th>
                <th>10</th>
           </tr>
           <tr>
                <th>00</th>
                <td class="bgg">0</td>
                <td>1</td>
                <td>3</td>
                <td>2</td>
           </tr>
           <tr>
                <th>01</th>
                <td>4</td>
                <td>5</td>
                <td class="bgr2">7</td>
                <td class="bgr2">6</td>
           </tr>
           <tr>
                <th>11</th>
                <td>C</td>
                <td class="bgr2">D</td>
                <td class="bgg">F</td>
                <td>E</td>
           </tr>
           <tr>
                <th>10</th>
                <td>8</td>
                <td class="bgr2">9</td>
                <td>B</td>
                <td>A</td>
           </tr>
        </table>
 <p>
 The possibilities for the first step are R1(0) = 8, R2(0) = 4, R3(0) = 2 or R4(0) = 1.
 Each possible result is closer to F than 0 is, and is not in the avoid-list.<br />
 Make a random choice of R2(0) = 4.
 </p>
 <p>
 The possibilities for the second step are R1(4) = C, R2(4) = 0, R3(4) = 6 or R4(4) = 5.
 The results C and 5 are closer to F than 4 is, and are not in the avoid-list.<br />
 Make a random choice of R4(4) = 5.
 </p>
 <p>
 The possibilities for the third step are R1(5) = D, R2(5) = 1, R3(5) = 7 or R4(5) = 4.
 The results D and 7 are closer to F than 5 is, but are in the avoid-list, a dead-end has been found.<br />
 Add 5 to the avoid-list, try the rule-path search again.
 </p>
 <p>
 With the addition of 5 to the avoid-list, a second try will find a four step rule-path, like: R2(0) = 4, R1(4) = C, R3(C) = E, R4(E) = F.
 </p>
 <p>
 Backward-chaining from F to 0 would have avoided the dead-end at square 5, and succeeded on the first try.
 </p>
 <p>
 If the goal was to go from F to 0, forward-chaining would miss the dead-end at square 5, while backward-chaining, from 0 to F, could hit or miss square 5.
 </p>
 <p>
 So the functional difference between forward-chaining and backward-chaining is that they expose different sets of dead-ends.
 </p>
 <h3>Dual Backward Chaining</h3>
        <p>
        If we were to start with the goal of going from the dead-end square 5 to square F, forward and backward chaining would fail.
        The only closer squares between 5 and F are D and 7, which are in the avoid list.
        There are no rules that would change two bits at a time, allowing squares D and 7 to be bypassed.
        </p>
        <p>
        It almost seems like we are missing something, since we know that we went from square 0 to 5 and from square 0 to F, above.
        </p>
        <p>
        We could check the hypothesis that backward-chaining from 5 and from F would produce rule-paths that eventually intersect, like at square 0.
        </p>
        <p>
        If there is an intersection of the two paths from 5 and F, the rule-path to execute would then be from 5 to the intersection, then from the intersection to F.
        </p>
        <p class="indent1">
        Backward-chaining from 5, avoiding (6, 7, 9, D), produces (1, 4).
        </p>
        <p class="indent1">
        Backward-chaining from F, avoiding (6, 7, 9, D), produces (B, E).
        </p>
        <p class="indent1">
        Looking at possible combinations between (1, 4) and (B, E), and the number of different bits, we get:
        </p>
        <p class="indent2">
        (E, 4) = 2, (E, 1) = 4, (B, 4) = 4, (B, 1) = 2.
        </p>
        <p class="indent1">
        Selecting (E, 4) from the combinations with the least number of different bits:
        </p>
        <p class="indent2">
        Backward-chaining from E, avoiding (6, 7, 9, D, F), produces (A, C).<br />
        Backward-chaining from 4, avoiding (6, 7, 9, D, 5), produces (0, C).<br />
        We have an intersection at C.
        </p>
        <p class="indent1">
        Or selecting (B, 1):
        </p>
        <p class="indent2">
        Backward-chaining from B, avoiding (6, 7, 9, D, F), produces (A, 3).<br />
        Backward-chaining from 1, avoiding (6, 7, 9, D, 5), produces (0, 3).<br />
        We have an intersection at 3.
        </p>
        <h3>Dual Forward Chaining</h3>
        <p>
         A few previously sampled squares can be randomly selected and tested for the possibility that the current state can forward chain to that state, then forward chain to the goal.
        </p>
        <p>
        This may produce a less than optimal rule-path, which can be checked for shortcuts.
        This seems reminiscent of real-life problem solving.
    </p>
    <h3>An intermediate bit-change goal</h3>
        <p class="indent1">
          If neither forward-chaining nor backward-chaining succeed, it is possible to identify a bit-change that is the most difficult to arrange.
          Causing that bit-change can become an intermediate goal, even to the point of increasing the number of bits different between the current state and the goal.
        </p>
    <h3>Rule chaining intersection restrictions</h3>
        <p>
        Imagine chaining together two rules, 0X0X&#8594;1X0X and 1XX1&#8594;1XX0.
        </p>
        <p>
        The result region of the first rule is not equal to the initial region of the second rule, they intersect at 1X01.
        </p>
        <p>
        This restricts the result region of the first rule, thereby restricting its initial region.
        </p>
        <p>
        This restricts the initial region of the second rule, thereby restricting its result region.
        </p>
        <p>
        The effective combination of rules is 0X01&#8594;1X01 and 1X01&#8594;1X00.
        </p>
        <p>
        If the rule combination was part of a larger chain of rules, the restriction effects would ripple up and down the chain.
        </p>
     <p>
        Likewise, intermediate regions, predicted in forward or backward chaining, may encounter or need only rules that they intersect, instead of being equal or subset.
        </p>
    <h3>Multiple Result States, more notes</h3>
        <p>
        The aggregate of rules of a multiple-result state includes at least one 0&#8594;X or 1&#8594;X bit position.
        </p>
        <p class="indent1">
        If the  0&#8594;X or 1&#8594;X bit position represents the only change, the rule may be used once or twice to elicit the change.
        </p>
        <p class="indent1">
        If the rule with a 0&#8594;X or 1&#8594;X bit position contains some other desirable change, and the goal region has an X in the same bit position, the rule may be used without caring what happens in the b&#8594;X position.
        </p>
        <p class="indent1">
        If the  rule with a 0&#8594;X or 1&#8594;X bit position contains some other desirable change, and can be followed with a rule that has a desired X&#8594;0 or X&#8594;1 in the same bit position, the rule may be used without caring what happens in the b&#8594;X position.
        </p>
        <p class="indent1">
        If a state in a multiple-result region has been sampled before, the next result can be predicted. To avoid the other possible change, the state may become an intermediate goal.
        </p>
        <p>
        It is reasonable to avoid the use of rules from multiple result regions, if at all possible, but the trade-offs seem reminiscent of real-life problem solving.
        </p>
 </div>
  <div id="conclude">
 <h2>Conclusion</h2>
 <p>
 It should be possible to write a program that creates rules through experience, improves rules by experimentation, uses rules to attain goals, and avoids the Combinatorial Explosion.
 </p>
 <p> 
   <i>The program is an expert of its own state.</i>
   To the extent that some state bits predictably affect the outside world, and the outside world predictably affects
        some bits, the program can understand and affect the outside world.
  </p>
  <p>
  The program should be portable to different physical systems, probably changing the goal regions, avoidance regions and the number of bits in the state.
  </p>
  <p>
  The State-Change rules learned in a physical system should be portable to a copy of the system.
  </p>
 <p>
 If the physical system the program runs in sustains damage, the program should be able to delete rules that no longer work and learn new rules.
 Goals can still be pursued, albeit in a less capable condition.
 </p>
 <p>
 The Largest Possible Region has been treated, above, as having all bit positions set to X.
 Due to poor planning, a poorly chosen initial state, or damage to a system, some bits in the system state will
 not change, or will stop changing.
 </p>
 <p>
 The program would have actions it can take, and each action would change the state bits.
 Without feedback, there can be no State-Change rules.
 If the program takes no action, something in the program state should still be updated, like a cycle counter, a time counter or a null action indicator.
 </p>
 <p>
 To avoid completely predictable behavior, whenever there is more than one possible choice of sample need or action, it should be chosen randomly.
 </p>
 </div>
 <div id="footer">
     <p>Contact/Feedback:&nbsp;<a href="mailto:earl.dukerschein@wisc.edu">Bitflogger</a></p>
     <p>B.S. Computer Science, 1980, NIU</p>
   <p>Web page Started: 10/20/2010, last changed: 1/04/2020</p>
  </div>
<div id="addendum">
  <h3>Addendum: False Geometry</h3>

  <p>When drawing a region on a K-Map, we are strongly tempted to refer to it as a (larger) square or a rectangle.  This is not accurate, it is false geometry.</p>

  <p>When you draw a square or rectangle on a piece of paper, there are parts of the figure that are interior, or &quot;in the middle&quot;.  In a region drawn on a K-Map, every square is on the edge, there are no interior squares.</p>

  <p>You might ask about the region that encompases the whole K-Map, aren't squares like 5,7,D and F in the middle?</p>

  <p>The apparent edges of a K-Map actually wrap around and are not really edges, but there is another possible edge.</p>

<p>It was shown in the first section that you cannot add a bit to a 2-bit axis to draw a larger K-Map.  We know that a 4-bit number has 16 possible values, and a 5-bit number has 32 possible values.<p>

  <p>You can imagine a 5-bit K-Map as being two 2-bit by 2-bit K-Maps meeting face to face.  One K-Map can be thought of as 0XXXX, the other as 1XXXX.</p>
 
  <p>Every square in the region 1XXXX will have 1 in its first bit position.</p>
  <p>For any square in the region 1XXXX, changing its first bit position to zero will identify a square that is adjacent (one bit different) and outside the region (first bit is not 1).</p>
  <p>Any non-X bit position in the region is an edge.</p>
  <p>Every square in a region is on every edge of the region.</p>
  <p>As shown by two adjacent regions, an edge is a bit position and has a 1-side and a 0-side.</p>
  <p>A region with more than one edge is at the intersection of those edges.</p>
  <p>The region XXXX has no edges, so all squares are in the middle</p>
  <p>A greater than 4-bit K-Map could be printed as multiple 4-bit maps.  A 6-bit K-Map would be (00XXXX, 01XXXX, 10XXXX, 11XXXX)</p>

<h3>Chaining</h3>

<p>Forward and backward chaining examples, given above, were easy due to any bit change 
being readily available, since it could be applied to any state in a region of all
X bit positions.</p>

<p>For regions that change one or more bits, that also have non-X bit positions, it can
be necessary to navigate the current, or intermediate, state to that region.</p>

<p>Navigating to a region to seek a bit change causes its own bit changes, which may be desired,
undesired, or unimportant.<p>

<h3>Combining</h3>
<p>After a calculation that results in a list of regions, you may want to combine the regions as much as possible.</p>
<p>A first step would be to combine regions that are adjacent and have the same X bit positions.</p>
<p>In the case of (0001, 001X, 100X, 1011), some are adjacent but do not have the same X bit positions.</p>
<p>The "adjacent parts" (see above) of adjacent regions can help.</p>
<p>The adjacent part of (0001, 001X) is 00X1.</p>
<p>The adjacent part of (1011, 100X) is 10X1.</p>
<p>00X1 and 10X1 can be combined to X0X1, which is a superset of 0001 and 1011.</p>
<p>The result is (X0X1, 001X, 100X), one less region.</p>

<h3>Second Level Regions</h3>
<p>Given a number of regions with some overlaps (level 1, L1), a second level (L2) can be considered to be all those region parts that are not overlapped.</p>
<p>Combining the L2 regions as much as possible, then comparing to the L1 regions, an L2 region may overlap more than one L1 region.</p>
<p>In that case, some squares used to confirm a region will also be in only one region.</p>
<p>This reduces the total number of squares that need to be sampled to confirm a number of regions.</p>
</div>
</body>
